# DetecÃ§Ã£o de Fraudes em TransaÃ§Ãµes Financeiras com Machine Learning

**Candidata:** Mirella Fontinelle (mlfm@cin.ufpe.br)  
**Eixo:** Machine Learning â€” PS Ligia 2026

Este repositÃ³rio contÃ©m o pipeline completo desenvolvido para o Desafio  Individual do Processo Seletivo da Liga AcadÃªmica de InteligÃªncia Artificial  (Ligia) â€” CIn/UFPE, eixo de Aprendizado de MÃ¡quina.

## ğŸ“‚ OrganizaÃ§Ã£o do RepositÃ³rio
```
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ notebook_desafio_ml.ipynb       # Pipeline completo: EDA, prÃ©-processamento, 
â”‚                              # treinamento, SHAP e geraÃ§Ã£o da submissÃ£o
â”œâ”€â”€ models/
â”‚   â””â”€â”€ modelo_xgboost_ligia.pkl     # Modelo final serializado
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ relatorio_tecnico.pdf  # RelatÃ³rio tÃ©cnico no padrÃ£o IEEE
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â””â”€â”€ README.md
```

## ğŸ“Š Dados

Os datasets nÃ£o estÃ£o incluÃ­dos no repositÃ³rio devido ao tamanho dos arquivos.
Para reproduzir os resultados:

1. Acesse a competiÃ§Ã£o oficial no Kaggle e baixe `train.csv` e `test.csv`.
2. Crie uma pasta `data/` na raiz do projeto.
3. Insira os arquivos CSV dentro de `data/`.

## ğŸš€ Como Executar

### 1. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

### 2. Configure o caminho dos dados

No notebook, certifique-se de que o caminho dos dados aponta para `../data/`.

### 3. Execute o notebook

Abra e execute `notebooks/desafio_ml.ipynb` do inÃ­cio ao fim. O notebook estÃ¡
organizado nas seguintes etapas:

- **EDA**: AnÃ¡lise exploratÃ³ria completa com visualizaÃ§Ãµes
- **PrÃ©-processamento**: TransformaÃ§Ãµes e preparaÃ§Ã£o do pipeline
- **Modelagem**: Treinamento e comparaÃ§Ã£o entre RegressÃ£o LogÃ­stica, 
  Random Forest e XGBoost com validaÃ§Ã£o cruzada estratificada
- **Interpretabilidade**: AnÃ¡lise SHAP global (Summary Plot) e local 
  (Waterfall Plot)
- **SubmissÃ£o**: GeraÃ§Ã£o automÃ¡tica de `submission_final_ligia.csv` 
  ao final do notebook

## ğŸ§  DecisÃµes TÃ©cnicas Principais

| DecisÃ£o | Justificativa |
|---|---|
| ROC-AUC como mÃ©trica | Robusta a desbalanceamento; mede capacidade de ordenaÃ§Ã£o de risco |
| `scale_pos_weight â‰ˆ 577` | PenalizaÃ§Ã£o proporcional ao desbalanceamento sem modificar os dados |
| SMOTE descartado | Risco de data leakage quando aplicado antes da validaÃ§Ã£o cruzada |
| StratifiedKFold (5 folds) | Preserva proporÃ§Ã£o de fraudes em cada fold â€” essencial com 0,17% de positivos |
| XGBoost com early stopping | Evita sobreajuste; convergÃªncia mÃ©dia em â‰ˆ559 Ã¡rvores de um limite de 5000 |
| SHAP para interpretabilidade | Garante rastreabilidade das decisÃµes; consistente com os coeficientes do modelo linear |

## ğŸ“ˆ Resultados

| Modelo | ROC-AUC (CV) | Desvio PadrÃ£o |
|---|---|---|
| RegressÃ£o LogÃ­stica | 0,9805 | Â±0,0114 |
| Random Forest | 0,9658 | Â±0,0149 |
| XGBoost (baseline) | 0,9829 | Â±0,0100 |
| **XGBoost (tuned)** | **0,9872** | **Â±0,0078** |
